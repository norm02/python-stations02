{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB3qZ6qOCG9c"
      },
      "source": [
        "| Version | Published Date| Details |\n",
        "| -- | -- | -- |\n",
        "| ver.1.0.0 | 2023/8/29 | 初版 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqbqeb4aNNN6"
      },
      "source": [
        "# Webスクレイピングをやってみよう\n",
        "\n",
        "WindowsやMacでなにか作業をするとき，インターネットを使わずに行うことは稀でしょう。今お使いのGoogle Colaboratoryですら，インターネットを使って実現されています。\n",
        "\n",
        "**Webスクレイピング** は，プログラムを使ってWebからコンテンツをダウンロードして処理することです。たとえばば，Googleは多数のWebスクレイピングプログラムを実行して **クローリング** を行い，検索エンジン用にWebページの索引を作っています。このStationでは，Pythonで簡単にWebスクレイピングをするのに役立つ次のようなモジュールについて学びます。\n",
        "\n",
        "- requests\n",
        "- bs4\n",
        "- selenium\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPorC_HbVM0L"
      },
      "source": [
        "## `requests` モジュールを用いてWebサイトからファイルをダウンロードする\n",
        "\n",
        "Pythonの `requests` モジュールを使うと，ネットワークに関する複雑な問題に対処することなく，Webから簡単にファイルをダウンロードできます。まずはいつものように `requests` を `import` しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ImsVQ6L-VgV6"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbBpFHZKZ9Sd"
      },
      "source": [
        "`requests.get()` はダウンロードするURLを文字列として受け取ります。 `requests.get()` の戻り値を `type()` で調べてみると `Response` オブジェクトであることがわかります。このオブジェクトにはWebサーバーのリクエストに対するレスポンス (応答) が格納されています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q2HM1sezVhZE"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.gutenberg.org/files/1787/1787.txt'\n",
        "r = requests.get(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2abwPluzEl6"
      },
      "source": [
        "`url` に格納しているURL https://www.gutenberg.org/files/1787/1787.txt はインターネット上に公開されている「ハムレット」のテキストファイルです。このWebページに対するリクエストが成功したかどうかは `Response` オブジェクトの `statud_code` を調べればわかります。もしこの値が `requests.code.ok` であれば成功です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HW3CJLQVvVy"
      },
      "outputs": [],
      "source": [
        "type(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWveojNgaPdJ"
      },
      "outputs": [],
      "source": [
        "r.status_code == requests.codes.ok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvBeCyKvzMov"
      },
      "source": [
        "ちなみにHTTPプロトコルで「OK」の状態コードは `200` です。「Not Found」を表す状態コードの `404` は見たこともあるでしょう。HTTPの状態コードの完全なリストとその意味は [Wikipedia](https://ja.wikipedia.org/wiki/HTTP%E3%82%B9%E3%83%86%E3%83%BC%E3%82%BF%E3%82%B9%E3%82%B3%E3%83%BC%E3%83%88%E3%82%99) を参照してください。\n",
        "\n",
        "リクエストが成功すると，Webページがダウンロードされ `Response` オブジェクトの `text` 属性に文字列として格納されます。 `len(r.text)` を呼び出してみると211,000文字以上あることがわかります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSVRGOTRaRwh"
      },
      "outputs": [],
      "source": [
        "len(r.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72vkjt9Vzgo9"
      },
      "source": [
        "`r.text[:300]` を呼び出して，冒頭300文字を表示しましょう。もしリクエストが失敗し 「 `Failed to establish a new connection` (新たな接続の確立に失敗しました)」や「 `Max retries exceeded` (最大試行回数を超えました)」といったエラーメッセージが表示されたら，インターネットの接続を確認してください。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLDhOkAPaTNR"
      },
      "outputs": [],
      "source": [
        "r.text[:300]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYs7dU4ZaanF"
      },
      "source": [
        "サーバへの接続は複雑です。そのため起こりうる問題すべてを列挙することはできません。エラーメッセージを引用して検索すれば，よくある原因を見つけられるでしょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wduMOihs2bIF"
      },
      "source": [
        "## エラーをチェックする\n",
        "\n",
        "先に書いたように `Response` オブジェクトには `status_code` 属性があり `requests.codes.ok` と比較することによりダウンロードが成功したかどうかを調べられます。もっと簡単に成功したかどうかを調べるには `Response` オブジェクトの `raise_for_status` メソッドを呼び出します。\n",
        "\n",
        "このメソッドはファイルのダウンロードが失敗すれば例外を発生させ，成功すればなにもしません。\n",
        "\n",
        "例えば、次の例では example.com という存在しないURLに対してリクエストを送っています。以下を実行すると HTTPError が表示されますが、これは正常な挙動です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42d7_4tUaWOC"
      },
      "outputs": [],
      "source": [
        "res = requests.get('https://www.example.com/download-helloworld')\n",
        "res.raise_for_status()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXeFU_7-3CGo"
      },
      "source": [
        "`raise_for_status()` メソッドは，ダウンロードが失敗したら必ずプログラムを停止するのにとてもよい方法です。予期せぬエラーが起きたらすぐにプログラムを停める方がよい場合が多いからです。\n",
        "\n",
        "ダウンロード失敗がプログラムを停止させるほどのものでないなら `raise_for_status()` の行を [try/except](https://docs.python.org/ja/3/tutorial/errors.html) 文で囲むことにより，異常終了せずにエラーを処理できます。Pythonの例外についての詳しい説明は省きますが，興味のある方はリンクから公式ドキュメントを読んだり，調べたりしてみてください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe4qzzGz2-Xx"
      },
      "outputs": [],
      "source": [
        "res = requests.get('https://www.example.com/download-helloworld')\n",
        "try:\n",
        "    res.raise_for_status()\n",
        "except Exception as exc:\n",
        "    print(f'問題あり: {exc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrDntoVi87rj"
      },
      "source": [
        "`requests.get()` を呼び出したら，必ず `raise_for_status()` を呼び出すようにしましょう。プログラムの実行を継続する前に，実際にダウンロードされたことを確認する方がよいからです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sDsgnPWDTVd"
      },
      "source": [
        "# HTML\n",
        "\n",
        "実際にWebページを解析する前に，HTMLの基本について学びましょう。またWebブラウザの強力な開発者向けツールの操作方法を覚えて，簡単にWebからの情報をスクレイピングできるようにしましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCqpvrwk42CP"
      },
      "source": [
        "## HTMLについて学習するには\n",
        "\n",
        "**HTML** (HyperText Markup Language) は，Webページを記述するための記法です。このStationではHTMLの基本を知っていることを前提にしています。もしHTMLに明るくない方は，次のサイトをおすすめします。\n",
        "\n",
        "- https://developer.mozilla.org/ja/docs/Learn/HTML (日本語)\n",
        "- https://htmldog.com/guides/html/beginner/ (英語)\n",
        "- https://www.codecademy.com/learn/learn-html/ (英語)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04eMm59c7wZZ"
      },
      "source": [
        "## HTMLについてざっとおさらい\n",
        "\n",
        "HTMLについて調べてからしばらく間がある方もいることでしょう。ここでは簡単に基本をおさらいします。HTMLファイルはプレーンテキストであり，一般に `.html` や `.htm` といった拡張子を持ちます。\n",
        "\n",
        "テキストは `<>` で記述された **タグ (Tag)** で囲まれています。タグはWebページの構成や成形方法をブラウザに伝えます。開始タグ `<>` と終了タグ `</>` でテキストを囲むと **要素** になります。 **内部テキスト** とは，開始タグと終了タグで囲まれた内容のことです。たとえば，次のHTMLはブラウザに \"Hello, world!\" と表示するものですが `<strong>` の指定により \"Hello\" の部分を強調表示します。\n",
        "\n",
        "```html\n",
        " <strong>Hello</strong>, world!\n",
        " ```\n",
        "\n",
        " このHTMLはブラウザ上では以下のように表示されます。\n",
        "\n",
        " <img src=\"https://drive.google.com/uc?id=1NjmBhGf1j67TWXl244HeeZxIFh_ks-R7\" width=\"480px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lJkYY9tyxMC"
      },
      "source": [
        "開始タグ `<strong>` は囲んだテキストを強調表示することを意味します。そして終了タグ `</strong>` は強調表示するテキストの終端を表します。\n",
        "\n",
        "HTMLにｋはこれ以外にもさまざまなタグがあります。タグには `<` と `>` の中に **属性** を指定できるものもありまし。たとえば `<a>` タグはリンクとなるテキストを囲むものですが，リンク先のURLは `href` 属性に記述します。\n",
        "\n",
        "```html\n",
        " Al's free <a href=\"https://inventwithpython.com\">Python books</a>.\n",
        "```\n",
        "\n",
        "このHTMLをブラウザで表示すると以下のようになります。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1d0TxG80pj_5NL7ttxpp2e1GFyoxIktlE\" width=\"480px\">\n",
        "\n",
        "要素には `id` 属性をつけてページ上の要素を識別するのに使えます。Webスクレイピングのプログラムを書くときには `id` 属性を用いて要素を探すプログラムを組むことがよくあります。そこで，ブラウザの開発者ツールを使って属性の `id` を探すと便利です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7rXGLc-6ppy"
      },
      "source": [
        "## WebページのソースHTMLを見る\n",
        "\n",
        "プログラムの処理対象となるWebページのソースHTMLを調べるには，Webブラウザのぺージ上で右クリック (macOSでは `Ctrl` キーを押しながらクリック) し [ページのソースを表示] のメニュー項目を選びます。するとブラウザが実際に取得したテキストが表示されます。このHTMLに基づいて，ブラウザはWebページを整形して表示します。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1Qrw5zpGTJ-qfgdZ5IX4voBrCvzBA6XPf\" width=\"480px\">\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1Z16YsRKFg6yMaXHUpab6arkx0oasYxGL\" width=\"480px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B0pF_Az9n1A"
      },
      "source": [
        "お気に入りのWebサイトのソースHTMLを見てみましょう。ソースの内容を完全に理解する必要はありません。簡単なWebスクレイピングプログラムを書くのに，HTMLに熟達する必要はないのです。Webサイトを作るわけではないのですから，既存のサイトからデータを取り出すために必要な知識があれば十分です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1wrZiTqA1Xa"
      },
      "source": [
        "## ブラウザの開発者ツールを開く\n",
        "\n",
        "Webページのソースを見るだけでなく，開発者ツールを使ってHTMLを解析してみましょう。ChromeやEdgeには開発者ツールが内蔵されていて， `F12` キーを押すと表示されます。もう一度 `F12` キーを押すと開発者ツールは消えます。Chromeの場合では **メニュー** → **その他のツール** → **デベロッパーツール** や `Ctrl - Shift - I` でも開発者ツールを表示できます。macOSでは `⌘ - Option - I` でChromeの開発者ツールが開きます。FirefoxやSafariにも同様の機能がありますが，ここでは詳しく書きません。利用している人は自分で調べてみてください。\n",
        "\n",
        "ブラウザの開発者ツールを使うと，Webページ上のありとあらゆる場所を右クリックして **要素の調査** や **検証** を行い，対応するHTML要素を表示できます。Webスクレイピングをするプログラムを作るとき，HTML解析に着手するのに便利です。\n",
        "\n",
        "### HTMLを解析するのに正規表現を使わない\n",
        "\n",
        "正規表現を学んだみなさんなら，文字列に格納されたHTMLから特定の部分を見つけるのに正規表現はうってつけに見えます。しかし現実では正規表現はこの用途ではあまり使われません。HTMLの書き方にはさまざまな方法があり，いずれも正しいHTMLとみなされます。そのため可能なバリエーションすべてに対応しようとするのは厄介で間違いが起こりやすいです。Beautiful SoupのようなHTMLを解析するモジュールを使えば，バグになりにくくなります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLJWJiBCFwf4"
      },
      "source": [
        "## 開発者ツールを使ってHTML要素を検索する\n",
        "\n",
        "次に必要なのは，Webページ上で関心のある情報に対応するのはHTMLのどの部分なのか見つけることです。\n",
        "\n",
        "ここでブラウザの開発者ツールが役に立ちます。例として https://tenki.jp/ から天気予報のデータを取り出すプログラムを書いてみます。コードを書く前に少し調べましょう。ブラウザでこのサイトを開いて郵便番号100-0001を探すと，その地域の天気予報を表示します。\n",
        "\n",
        "ここでは，郵便番号に対応する天気情報を取り出すことにしましょう。 [千代田区の天気](https://tenki.jp/forecast/3/16/4410/13101/) のページ上の天気アイコンの箇所で右クリックして，メニューから「要素を調査」や「検証」を選択してください。開発者ツールが開いて，対応するHTMLを表示します。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=13RnI2W0SWe9PHEhVbM2BhKEKh5jWt6d6\" width=\"720px\">\n",
        "\n",
        "なお，Webサイト https://tenki.jp/ のデザインが変わったら，以下の手順をやり直して要素を確認する必要があります。\n",
        "\n",
        "開発者ツールを見ると，Webページ上で **今日の天気** に対応するHTMLは次の箇所です。\n",
        "\n",
        "```html\n",
        "<p class=\"weather-telop\">曇のち晴</p>\n",
        "```\n",
        "\n",
        "これがまさに探していた情報です。天気予報の情報は `<div>` 要素の中に含まれており `weather-icon` というCSSクラスを持つようです。開発者ツールをこの要素の上で右クリックして `Copy` → `CSS Selector` または `Copy selector` を選ぶと，次のような文字列をクリップボードにコピーできます。\n",
        "\n",
        "```css\n",
        "#main-column > section > div.forecast-days-wrap.clearfix > section.today-weather > div.weather-wrap.clearfix > div.weather-icon > p\n",
        "```\n",
        "\n",
        "この文字列はCSSセレクタといって，後述のBeautiful Soupの `select()` やSeleniumの `find_element(By.CSS_SELECTOR, ...)` に渡してHTML要素を取得できます。それではBeautifulSoupを用いて文字列を取得してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc8MJuiWS5Fe"
      },
      "source": [
        "# bs4モジュールを使ってHTMLを解析する\n",
        "\n",
        "Beautiful Soup はHTMLページから情報を抽出するモジュールで，この目的では正規表現よりも優れています。Beautiful Soup のモジュール名は `bs4` (Beautiful Soup Version 4) です。\n",
        "\n",
        "このStationでは Beautiful Soup によってHTMLファイルを **パース (Parse)** することを学びます。パースとは，部分を識別できるように構文解析することです。構文解析器のことを **パーサー (Parser)** と呼びます。\n",
        "\n",
        "単純に見えるHTMLでも，実際にはさまざまなタグが使われています。複雑なWebサイトであれば，すぐにもっと込み入ったものになります。このような場合に Beautiful Soup を使うとHTMLを簡単に扱えて非常に便利です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E87NTy4hc7hc"
      },
      "outputs": [],
      "source": [
        "import requests, bs4\n",
        "res = requests.get('https://tenki.jp')\n",
        "res.raise_for_status()\n",
        "tenkijp = bs4.BeautifulSoup(res.content, 'html.parser')\n",
        "type(tenkijp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU8yVt_EhiBG"
      },
      "source": [
        "## HTMLからBeautifulSoupオブジェクトを生成する\n",
        "\n",
        "このコードでは `requests.get()` を用いて tenki.jp のウェブサイトからページをダウンロードし，レスポンスの `content` 属性を `bs4.BeautifulSoup()` に渡しています。 `BeautifulSoup` オブジェクトは，変数 `tenkijp` に格納されています。\n",
        "\n",
        "`BeautifulSoup()` の第2引数には，解析するパーサーを指定します。 `html.parser` は Python に付属しているものです。この他にサードパーティーの高速な `lxml` パーサーを使うことも可能です。\n",
        "\n",
        "`BeautifulSoup` オブジェクトを取得できたら，そのメソッドを用いてHTMLの特定の部分を見つけられます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGfVDgnZk4Lc"
      },
      "source": [
        "## `select()` メソッドを用いて要素を見つける\n",
        "\n",
        "`BeautifulSoup` オブジェクトの `select()` メソッドに，検索したい要素の **CSSセレクタ (CSS Selector)** を渡して呼び出すと，Webページの要素を取得できます。セレクタとは，HTMLページから検索対象を指定するためのパターンのことです。テキストから検索するための正規表現のようなものです。\n",
        "\n",
        "CSSセレクタの文法をすべて説明するのは困難なので，ここではセレクタを簡単に説明するだけにとどめます。以下によく使われるCSSセレクタのパターンを示します。\n",
        "\n",
        "|  select() に渡すセレクタ  |  マッチする対象  |\n",
        "| ---- | ---- |\n",
        "|  `soup.select('div')`  |  すべての `<div>` 要素  |\n",
        "|  `soup.select('#author')`  |  `id` 属性が `author` である要素  |\n",
        "|  `soup.select('.notice')`  | CSSクラス属性が `notice` である全要素  |\n",
        "|  `soup.select('div span')`  | `<div>` 要素の中のすべての `<span>` 要素  |\n",
        "|  `soup.select('div > span')` | `<div>` 要素の直下のすべての `<span>` 要素 (間に他の要素がない) |\n",
        "|  `soup.select('input[name]')` | `name` 属性 (値は任意) を持つすべての `<input>` 要素 |\n",
        "|  `soup.select('input[type=button]')` | `type` 属性の値が `button` であるすべての `<input>` 要素 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_CXo4jaq4-b"
      },
      "source": [
        "さまざまなセレクタのパターンを組み合わせることで，複雑な検索が可能です。例えば `soup.select('p #author')` は `<p>` 属性の中にあって `id` 属性が `author` である要素にマッチします。セレクタを自分で書くのではなく，先に書いたとおりにブラウザ上で右クリックして「要素の調査」をし，開発ツール上のCSSセレクタをクリップボードにコピーして，ソースコードに貼り付けることもできます。\n",
        "\n",
        "`select()` メソッドは `Tag` オブジェクトのリストを返します。 `Tag` オブジェクトは Beautiful Soup におけるHTML要素の表現です。リストには `BeautifulSoup` オブジェクトのHTMLの中でマッチしたすべての要素が含まれています。 `Tag` オブジェクトは `str()` 関数に渡して，それが表現する要素を文字列として取得できます。 `Tag` オブジェクトには `attrs` 属性もあって，タグのすべての属性を辞書として保持しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rRCG3HD3iGix"
      },
      "outputs": [],
      "source": [
        "import bs4\n",
        "res = requests.get('https://lp.techbowl.co.jp/')\n",
        "res.raise_for_status()\n",
        "example_soup = bs4.BeautifulSoup(res.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeVjomqm1Yw9"
      },
      "source": [
        "このコードではTechTrainの紹介LPから `id=\"background\"` である要素を取り出しています。`select('#background')` を呼び出すと `id=\"background\"` であるすべての要素のリストが返ってきます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tMAJt-co1cBT"
      },
      "outputs": [],
      "source": [
        "elems = example_soup.select('#background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKg5Us520YX1"
      },
      "outputs": [],
      "source": [
        "type(elems[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2qMY80B0g-H"
      },
      "source": [
        "`elems` は `Tag` オブジェクトのリストです。この `Tag` オブジェクトのリストを変数 `elems` に格納し `len(elems)` を見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaN1F5Zn0TWI"
      },
      "outputs": [],
      "source": [
        "len(elems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yEzAkQL16RB"
      },
      "source": [
        "ここで `1` が返ってきますね。つまりマッチしたのは1つであったことがわかります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Eyy27Mg0lVf"
      },
      "outputs": [],
      "source": [
        "elems[0].getText()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHzFnzOH2IPT"
      },
      "source": [
        "要素の `getText()` メソッドを呼び出すと，要素の内部テキストを取得できます。内部テキストは開始タグと終了タグの間の内容なので，この場合は `優秀なエンジニアって…` からはじまる文章が取れることがわかります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SzC9nhi0piA"
      },
      "outputs": [],
      "source": [
        "str(elems[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVrsLFVX2f6t"
      },
      "source": [
        "要素を `str()` にわたすと，開始タグと終了タグを含む文字列を返します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGjci3Ri1OG5"
      },
      "outputs": [],
      "source": [
        "elems[0].attrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1Ice5nQ2ouA"
      },
      "source": [
        "最後に `attrs` は要素の属性を辞書として保存しています。この場合は `id` とその値 `background` を持つ辞書になります。また見た目を表すためのクラスがいくつも指定されていることがわかります。\n",
        "\n",
        "`BeautifulSoup` オブジェクトからすべての `<p>` 要素を取り出すことも可能です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qnljIn4j1iG0"
      },
      "outputs": [],
      "source": [
        "p_elems = example_soup.select('p')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sUijy9956Re"
      },
      "source": [
        "この例では `select()` は88個の要素からなるリストを返します。これを `p_elems` に格納し `p_elems[0]` から `p_elems[2` を `str()` に渡すと，各要素を文字列として取得できます。また `getText()` を呼び出すと，内部テキストを取得できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTpy1Wia4svI"
      },
      "outputs": [],
      "source": [
        "len(p_elems)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbtffyF04u63"
      },
      "outputs": [],
      "source": [
        "str(p_elems[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKbtB9Bp5ocB"
      },
      "outputs": [],
      "source": [
        "p_elems[0].getText()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXN_xNAY5rau"
      },
      "outputs": [],
      "source": [
        "str(p_elems[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bl3pcdE5vBZ"
      },
      "outputs": [],
      "source": [
        "p_elems[1].getText()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vHHNuGF5yEP"
      },
      "outputs": [],
      "source": [
        "str(p_elems[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-I-Q2M845z9S"
      },
      "outputs": [],
      "source": [
        "p_elems[2].getText()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F71xRGrB54hm"
      },
      "source": [
        "## 要素の属性からデータを取得する\n",
        "\n",
        "`Tag` オブジェクトの `get()` メソッドを用いると，要素の属性値を取得するのが簡単です。このメソッドに属性値を渡すと，その属性値を返します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UcU9MNJd52MF"
      },
      "outputs": [],
      "source": [
        "import bs4\n",
        "res = requests.get('https://lp.techbowl.co.jp/')\n",
        "res.raise_for_status()\n",
        "soup = bs4.BeautifulSoup(res.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YGDkxUgG8dfg"
      },
      "outputs": [],
      "source": [
        "span_elem = soup.select('span')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRG-G6_r8hUn"
      },
      "outputs": [],
      "source": [
        "str(span_elem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY_oNSaG8i7X"
      },
      "outputs": [],
      "source": [
        "span_elem.get('class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn0lF8q58nce"
      },
      "outputs": [],
      "source": [
        "span_elem.get('non_ecistent_attribute') == None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29RjmRuw8vfe"
      },
      "outputs": [],
      "source": [
        "span_elem.attrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbP3fBb49Pf8"
      },
      "source": [
        "# 確認テスト\n",
        "\n",
        "[TechTrainのMission一覧ページ](https://techtrain.dev/missions) を使って実際にスクレイピングをしてみましょう。\n",
        "\n",
        "1. 企業Missionは全部で何件ありますか？\n",
        "2. 企業Missionのうち名前に \"iOS\" を含むものはいくつありますか？\n",
        "3. Missionには `HTML` や `JavaScript` といったタグがついています。タグは全部で何種類ありますか？重複を削除した上で答えてください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwaazo7C9YCW"
      },
      "outputs": [],
      "source": [
        "import bs4\n",
        "res = requests.get('https://techtrain.dev/missions')\n",
        "res.raise_for_status()\n",
        "results = bs4.BeautifulSoup(res.content, 'html.parser')\n",
        "type(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "id": "Vy4e1hWcUs9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = results.select(\".mt-1\")"
      ],
      "metadata": {
        "id": "gfBvuoceUuQT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(m)"
      ],
      "metadata": {
        "id": "rmgEbw11Vw-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(m)"
      ],
      "metadata": {
        "id": "oouB096nWqaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = results.getText()"
      ],
      "metadata": {
        "id": "3tbSlwc8YJkh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = str(txt)"
      ],
      "metadata": {
        "id": "hnicxKWiYkys"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "id": "hUqtOPVpY8_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text.count(\"iOS\")"
      ],
      "metadata": {
        "id": "hjKh2VEXZ2Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_types = set()\n",
        "for tag in results.find_all():\n",
        "    tag_types.add(tag.name)\n",
        "\n",
        "print(len(tag_types))"
      ],
      "metadata": {
        "id": "oJK3TJ1ScDoo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}